{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, cwd)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from keras.models import load_model\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.get_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.importData import importData\n",
    "from module.toWordList import toWordList\n",
    "from module.steamingWiki import steamingWiki\n",
    "from module.makeModelGensim import makeModelGensim\n",
    "from module.toVectore import toVectore\n",
    "from module.modelLSTM import modelLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiSource\t\t\t= 'idwiki'\n",
    "answerData\t\t\t= 'DataAnswerExam_SMP.csv'\n",
    "# answerData\t\t\t= 'aes.csv'\n",
    "# answerData\t\t\t= 'aesnormal.csv'\n",
    "#questionData\t\t= 'DataQuestionExam_SMP.csv'\n",
    "questionData\t\t= 'qes.csv'\n",
    "dirData\t\t\t\t= cwd+'/data/'\n",
    "corpusInput\t\t\t= wikiSource+'.bz2'\n",
    "wikiOutput\t\t\t= wikiSource+'.txt'\n",
    "fileExtension\t\t= 'bin'\n",
    "trainingAlgoritm\t= 1\n",
    "numDimension\t\t= 200\n",
    "modelOutput\t\t\t= wikiSource+'_word2vec_'+str(numDimension)+'_'+str(trainingAlgoritm)+'.'+fileExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dAnswer, dQuestion = importData(answer= dirData+answerData, question= dirData+questionData).openData()\n",
    "\n",
    "if not(os.path.exists(dirData+modelOutput)):\n",
    "\tif not(os.path.exists(dirData+wikiOutput)):\n",
    "\t\tsteamingWiki(corpusInput=corpusInput, wikiOutput=wikiOutput).execute()\n",
    "\tmakeModelGensim(wikiOutput=wikiOutput, modelOutput=modelOutput, numDimension=numDimension, trainingAlgoritm=trainingAlgoritm).execute()\n",
    "\n",
    "if fileExtension != 'bin':\n",
    "\tmodel = gensim.models.word2vec.Word2Vec.load(dirData+modelOutput)\n",
    "else:\n",
    "\tmodel = gensim.models.KeyedVectors.load_word2vec_format(dirData+modelOutput, unicode_errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msea =[]\n",
    "maea =[]\n",
    "kappa = []\n",
    "file1 = io.open(\"small.txt\", \"w\")\n",
    "file2 = io.open(\"all.txt\", \"w\")\n",
    "filea = io.open(\"ma.txt\", \"w\")\n",
    "fileb = io.open(\"mb.txt\", \"w\")\n",
    "filec = io.open(\"mc.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safire/OneDrive/Kuliah/Tesis/module/modelLSTM.py:18: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  model.add(self.LSTM(200, dropout=0.5, recurrent_dropout=0.5, input_dim=200, return_sequences=rs))\n",
      "/home/safire/OneDrive/Kuliah/Tesis/module/modelLSTM.py:18: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, dropout=0.5, recurrent_dropout=0.5, return_sequences=False, input_shape=(None, 200...)`\n",
      "  model.add(self.LSTM(200, dropout=0.5, recurrent_dropout=0.5, input_dim=200, return_sequences=rs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 333,729\n",
      "Trainable params: 333,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safire/OneDrive/Kuliah/Tesis/module/modelLSTM.py:18: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, dropout=0.5, recurrent_dropout=0.5, return_sequences=True, input_shape=(None, 200...)`\n",
      "  model.add(self.LSTM(200, dropout=0.5, recurrent_dropout=0.5, input_dim=200, return_sequences=rs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, None, 200)         320800    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 392,865\n",
      "Trainable params: 392,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 12s 177ms/step - loss: 5.9945 - mean_absolute_error: 2.0603\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 4s 55ms/step - loss: 2.3474 - mean_absolute_error: 1.2441\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 1.9064 - mean_absolute_error: 1.1343\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 1.9136 - mean_absolute_error: 1.0233\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 2.2383 - mean_absolute_error: 1.2651\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 1.8815 - mean_absolute_error: 1.0971\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 1.4291 - mean_absolute_error: 0.9266\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 3s 49ms/step - loss: 1.2845 - mean_absolute_error: 0.8746\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 3s 48ms/step - loss: 1.4844 - mean_absolute_error: 0.9283\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 3s 42ms/step - loss: 1.6230 - mean_absolute_error: 0.9892\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 7.5228 - mean_absolute_error: 2.3755\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 3.0118 - mean_absolute_error: 1.4577\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 8s 123ms/step - loss: 3.0495 - mean_absolute_error: 1.4730\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 2.7158 - mean_absolute_error: 1.3011\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 2.1350 - mean_absolute_error: 1.2210\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 2.3269 - mean_absolute_error: 1.2855\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 8s 117ms/step - loss: 1.5084 - mean_absolute_error: 0.9951\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 9s 135ms/step - loss: 1.6878 - mean_absolute_error: 1.0006\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 1.5775 - mean_absolute_error: 0.9677\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 1.4898 - mean_absolute_error: 1.0002\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 333,729\n",
      "Trainable params: 333,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, None, 200)         320800    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                67840     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 392,865\n",
      "Trainable params: 392,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "68/68 [==============================] - 11s 166ms/step - loss: 6.9976 - mean_absolute_error: 2.1916\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 4s 63ms/step - loss: 2.2340 - mean_absolute_error: 1.2265\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 1.5525 - mean_absolute_error: 0.9260\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 4s 56ms/step - loss: 1.5974 - mean_absolute_error: 0.9761\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 4s 61ms/step - loss: 1.0043 - mean_absolute_error: 0.8255\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.1530 - mean_absolute_error: 0.7974\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 3s 44ms/step - loss: 1.1437 - mean_absolute_error: 0.8311\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 3s 40ms/step - loss: 1.1347 - mean_absolute_error: 0.8516\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 3s 40ms/step - loss: 1.0212 - mean_absolute_error: 0.8427\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 3s 39ms/step - loss: 1.2043 - mean_absolute_error: 0.8382\n",
      "Epoch 1/10\n",
      "68/68 [==============================] - 16s 232ms/step - loss: 7.7043 - mean_absolute_error: 2.4223\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 5s 75ms/step - loss: 1.9839 - mean_absolute_error: 1.1235\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 2.5566 - mean_absolute_error: 1.3558\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.9650 - mean_absolute_error: 1.0882\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 5s 72ms/step - loss: 2.1008 - mean_absolute_error: 1.1306\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.8602 - mean_absolute_error: 1.0502\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.7655 - mean_absolute_error: 1.0786\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 6s 89ms/step - loss: 1.6779 - mean_absolute_error: 1.0127\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 9s 132ms/step - loss: 1.2312 - mean_absolute_error: 0.9254\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 1.0633 - mean_absolute_error: 0.7941\n"
     ]
    }
   ],
   "source": [
    "for x in (dQuestion.loc[:,'Essay_id'].values):\n",
    "\tif x in dAnswer.loc[:,'Essay_id'].values:\n",
    "\t\txdAnswer = dAnswer.loc[dAnswer['Essay_id'] == x]\n",
    "\t\txdQuestion = dQuestion.loc[dQuestion['Essay_id'] == x]\n",
    "\t\tcrossVal = KFold(n_splits=2, random_state=None, shuffle=True)\n",
    "\t\tresults = []\n",
    "\t\tresultaa = []\n",
    "\t\tresultbb = []\n",
    "\t\tresultkappaa = []\n",
    "\t\tresultkappab = []\n",
    "\t\tresultkappac = []\n",
    "\n",
    "\t\tcount = 1\n",
    "\n",
    "\t\tfor dx, dy in crossVal.split(xdAnswer):\n",
    "\t\t\tdf1 = pd.DataFrame() \n",
    "\t\t\tdf2 = pd.DataFrame() \n",
    "\t\t\tdfa = pd.DataFrame() \n",
    "\t\t\tdfb = pd.DataFrame() \n",
    "\t\t\tdfc = pd.DataFrame() \n",
    "\t\t\ttrainStudentAnswer = []\n",
    "\t\t\ttestStudentAnswer = []\n",
    "\t\t\ttrueAnswer = []\n",
    "\t\t\tquestion = []\n",
    "\t\t\t\n",
    "\t\t\tprint(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\t\t\ttrain, test= xdAnswer.iloc[dx], xdAnswer.iloc[dy]\n",
    "\t\t\t\n",
    "\t\t\txtrain = train.loc[:,['Answer']]\n",
    "\t\t\txtest = test.loc[:,['Answer']]\n",
    "\t\t\tytrain = train.loc[:,['Score']].values\n",
    "\t\t\tytest = test.loc[:,['Score']].values\n",
    "\t\t\t\n",
    "\t\t\t[trainStudentAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= False, question=xdQuestion.loc[:,'Question'].values[0])) for a1 in xtrain.values]\n",
    "\t\t\t[testStudentAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= False, question=xdQuestion.loc[:,'Question'].values[0])) for a1 in xtest.values]\n",
    "\t\t\t[trueAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= False, question=xdQuestion.loc[:,'Question'].values[0])) for a1 in xdQuestion.loc[:,['Answer']].values]\n",
    "\t\t\t[question.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= False, question=xdQuestion.loc[:,'Question'].values[0])) for a1 in xdQuestion.loc[:,['Question']].values]    \n",
    "\t\t\t\n",
    "\t\t\tdataAnswerXTrain, dataTrueAnswerX = toVectore(essays = trainStudentAnswer, trueAnswer=trueAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\t\t\tdataAnswerXTest, dataTrueAnswerY = toVectore(essays = testStudentAnswer, trueAnswer=trueAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\t\t\t\n",
    "\t\t\t#modelNetworka = modelLSTM().getModel()\n",
    "\t\t\t#modelNetworkb = modelLSTM().getModel(rs=True)\n",
    "\t\t\t#modelNetworkb = modelLSTM().biGetModel(inputD=(dataAnswerXTrain.shape[1], dataAnswerXTrain.shape[2]))\n",
    "\t\t\t#modelNetworkc = modelLSTM().siamenseModel(inputD=(dataAnswerXTrain.shape[1], dataAnswerXTrain.shape[2]))\n",
    "\t\t\t#modelNetworkd = modelLSTM().biSiamenseModel(inputD=(dataAnswerXTrain.shape[1], dataAnswerXTrain.shape[2]))\n",
    "\t\t\t#modelNetworka = load_model(dirData+'model/lstm_model_a'+str(x)+'.h5')\n",
    "\t\t\t#modelNetworkb = load_model(dirData+'model/lstm_model_b'+str(x)+'.h5')\n",
    "            \n",
    "            \n",
    "\n",
    "\t\t\t#modelNetworka.fit(dataAnswerXTrain, ytrain, batch_size=10, epochs=10)\n",
    "\t\t\t#modelNetworkb.fit(dataAnswerXTrain, ytrain, batch_size=10, epochs=10)\n",
    "\t\t\t#modelNetworkb.fit([dataAnswerXTrain, dataTrueAnswerX], ytrain, batch_size=25, epochs=100)\n",
    "\t\t\t#modelNetworkd.fit([dataAnswerXTrain, dataTrueAnswerX], ytrain, batch_size=10, epochs=10)\n",
    "\t\t\t#ypred = modelNetworka.predict(dataAnswerXTest)\n",
    "\t\t\t#ypredb = modelNetworkb.predict(dataAnswerXTest)\n",
    "\t\t\t#dfa.insert(0,'actual',ytest.flatten())\n",
    "\t\t\t#dfa.insert(1,'predict',np.around(ypred).flatten())\n",
    "\t\t\t#dfb.insert(0,'actual',ytest.flatten())\n",
    "\t\t\t#dfb.insert(1,'predict',np.around(ypredb).flatten())\n",
    "\t\t\t#filea.write(\"===========\"+str(x)+\"========= fold \"+str(count))\n",
    "\t\t\t#filea.write(str(dfa.values))\n",
    "\t\t\t#filea.write('\\n')\n",
    "\t\t\t#fileb.write(\"===========\"+str(x)+\"========= fold \"+str(count))\n",
    "\t\t\t#fileb.write(str(dfb.values))\n",
    "\t\t\t#fileb.write('\\n')\n",
    "\t\t\t#resultkappaa.append(cohen_kappa_score(ytest, np.around(ypred), weights='quadratic'))\n",
    "\t\t\t#resultkappab.append(cohen_kappa_score(ytest, np.around(ypredb), weights='quadratic'))\n",
    "\t\t\t#resultkappac.append(cohen_kappa_score(ytest, np.around(ypredc), weights='quadratic'))\n",
    "\t\t\t#count += 1\n",
    "\t\t#filea.write(\"=======================================================\")\n",
    "\t\t#filea.write('\\n')\n",
    "\t\t#filea.write(str(resultkappaa))\n",
    "\t\t#fileb.write(\"=======================================================\")\n",
    "\t\t#fileb.write('\\n')\n",
    "\t\t#fileb.write(str(resultkappab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
