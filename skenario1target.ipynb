{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, cwd)\n",
    "from module.importData import importData\n",
    "from module.toWordList import toWordList\n",
    "from module.steamingWiki import steamingWiki\n",
    "from module.makeModelGensim import makeModelGensim\n",
    "from module.toVectore import toVectore\n",
    "#from module.modelLSTM import modelLSTM\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.get_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiSource\t\t\t= 'idwiki'\n",
    "answerData\t\t\t= 'DataAnswerExam_SMP.csv'\n",
    "questionData\t\t= 'qes.csv'\n",
    "dirData\t\t\t\t= cwd+'/data/'\n",
    "corpusInput\t\t\t= wikiSource+'.bz2'\n",
    "wikiOutput\t\t\t= wikiSource+'.txt'\n",
    "fileExtension\t\t= 'bin'\n",
    "trainingAlgoritm\t= 0\n",
    "numDimension\t\t= 200\n",
    "modelOutput\t\t\t= wikiSource+'_word2vec_'+str(numDimension)+'_'+str(trainingAlgoritm)+'.'+fileExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dAnswer, dQuestion = importData(answer= dirData+answerData, question= dirData+questionData).openData()\n",
    "\n",
    "if not(os.path.exists(dirData+modelOutput)):\n",
    "\tif not(os.path.exists(dirData+wikiOutput)):\n",
    "\t\tsteamingWiki(corpusInput=corpusInput, wikiOutput=wikiOutput).execute()\n",
    "\tmakeModelGensim(wikiOutput=wikiOutput, modelOutput=modelOutput, numDimension=numDimension, trainingAlgoritm=trainingAlgoritm).execute()\n",
    "\n",
    "if fileExtension != 'bin':\n",
    "\tmodel = gensim.models.word2vec.Word2Vec.load(dirData+modelOutput)\n",
    "else:\n",
    "\tmodel = gensim.models.KeyedVectors.load_word2vec_format(dirData+modelOutput, unicode_errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal = KFold(n_splits=2, random_state=True, shuffle=True)\n",
    "\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay_id</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>3</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1</td>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>4</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Essay_id                                             Answer  Score  \\\n",
       "0           1  Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...      3   \n",
       "120         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "365         1  alumni; argument; hasil; example; teknik; imaj...      4   \n",
       "650         1  alumnus; agenda; laba; sampel; teknik; imajina...      5   \n",
       "125         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dAnswer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = dAnswer.loc[:,['Answer','TrueAnswer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Answer  \\\n",
       "0    Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...   \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "365  alumni; argument; hasil; example; teknik; imaj...   \n",
       "650  alumnus; agenda; laba; sampel; teknik; imajina...   \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.to_categorical(dAnswer.loc[:,['Score']], num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelLSTM(object):\n",
    "\tfrom keras.models import Sequential, Model\n",
    "\tfrom keras.layers import LSTM, Dense, Dropout, Bidirectional, Lambda, Dot, Subtract\n",
    "\timport keras.backend as K\n",
    "\tfrom keras import optimizers\n",
    "\n",
    "\tdef biSiamenseModel(self, inputD, euclidean=False):\n",
    "\n",
    "\t\tfrom keras.layers import Input, concatenate, subtract, dot\n",
    "\t\tfrom keras import backend as K\n",
    "\n",
    "\t\tdef euclidean_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\tsum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "\t\t\treturn K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\t\tdef manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.sum((K.abs(x - y)), axis=1, keepdims=True)\n",
    "\n",
    "\t\tdef exponent_neg_manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.exp(-K.sum(K.abs(x-y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "\t\tMA = Input(shape= inputD, dtype=\"float32\")\n",
    "\t\tMB = Input(shape= inputD, dtype=\"float32\")\n",
    "\n",
    "\t\tx = self.Bidirectional(self.LSTM(200, dropout=0.5, recurrent_dropout=0.5), input_shape=inputD)(MA)\n",
    "\n",
    "\t\ty = self.Bidirectional(self.LSTM(200, dropout=0.5, recurrent_dropout=0.5), input_shape=inputD)(MB)\n",
    "\n",
    "\t\t# a2 = (self.Lambda(function=lambda a: euclidean_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\n",
    "\t\tif euclidean:\n",
    "\t\t\ta2 = (self.Lambda(function=lambda a: euclidean_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\t\telse:\n",
    "\t\t\t#a2 = concatenate([x,y])\n",
    "\t\t\ta2 = self.Subtract()([x,y])\n",
    "\t\t\n",
    "\t\tout = self.Dense(4, activation='softmax')(a2)\n",
    "\n",
    "\t\tmodel = self.Model(inputs=[MA, MB], outputs=out)\n",
    "\t\tsgd = self.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\t\tmodel.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mae'])\n",
    "\n",
    "\t\tmodel.summary()\n",
    "\n",
    "\t\treturn model\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 200, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 400)          641600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 400)          641600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 400)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            1604        subtract_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,284,804\n",
      "Trainable params: 1,284,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 60s 154ms/step - loss: 0.1896 - mean_absolute_error: 0.3714\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 45s 115ms/step - loss: 0.1790 - mean_absolute_error: 0.3607\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 46s 118ms/step - loss: 0.1630 - mean_absolute_error: 0.3426\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 45s 116ms/step - loss: 0.1446 - mean_absolute_error: 0.3168\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.1326 - mean_absolute_error: 0.2958\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.1179 - mean_absolute_error: 0.2693\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.1128 - mean_absolute_error: 0.2505\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.1094 - mean_absolute_error: 0.2395\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.1082 - mean_absolute_error: 0.2295\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.1056 - mean_absolute_error: 0.2223\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 200, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 200, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 400)          641600      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 400)          641600      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 400)          0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1604        subtract_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,284,804\n",
      "Trainable params: 1,284,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.1833 - mean_absolute_error: 0.3645\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1694 - mean_absolute_error: 0.3493\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1524 - mean_absolute_error: 0.3273\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.1374 - mean_absolute_error: 0.3038\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 22s 55ms/step - loss: 0.1267 - mean_absolute_error: 0.2786\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1198 - mean_absolute_error: 0.2578\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1140 - mean_absolute_error: 0.2400\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1129 - mean_absolute_error: 0.2286\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1085 - mean_absolute_error: 0.2190\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.1051 - mean_absolute_error: 0.2112\n"
     ]
    }
   ],
   "source": [
    "for dx, dy in crossVal.split(dAnswer):\n",
    "\n",
    "\ttrainSAnswer = []\n",
    "\ttrainTAnswer = []\n",
    "\ttestSAnswer = []\n",
    "\ttestTAnswer = []\n",
    "\t\n",
    "\tprint(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\ttrain, test= dAnswer.iloc[dx], dAnswer.iloc[dy]\n",
    "\t\n",
    "\t\n",
    "\txtrain = train.loc[:,['Answer', 'TrueAnswer']]\n",
    "\txtest = test.loc[:,['Answer', 'TrueAnswer']]\n",
    "\tytraincat, idtrain = np.unique(train.loc[:,['Score']].values, return_inverse=True)\n",
    "\tytrain = keras.utils.to_categorical(idtrain, len(ytraincat))\n",
    "\tytestcat, idtest = np.unique(test.loc[:,['Score']].values, return_inverse=True)\n",
    "\tytest = keras.utils.to_categorical(idtest, len(ytestcat))\n",
    "\t#ytrain = keras.utils.to_categorical(train.loc[:,['Score']].values, num_classes=6)\n",
    "\t#ytest = keras.utils.to_categorical(test.loc[:,['Score']].values, num_classes=6)\n",
    "\t\n",
    "\t# bagian ini biar universal aja.\n",
    "\t\n",
    "\t[trainSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['Answer']].values]\n",
    "\t[trainTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['TrueAnswer']].values]\n",
    "\t[testSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['Answer']].values]\n",
    "\t[testTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['TrueAnswer']].values]\n",
    "\t\n",
    "\tvtrainSAnswer, vtrainTAnswer = toVectore(essays = trainSAnswer, trueAnswer=trainTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tvtestSAnswer, vtestTAnswer = toVectore(essays = testSAnswer, trueAnswer=testTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tmodelNetwork = modelLSTM().biSiamenseModel(inputD=(vtrainSAnswer.shape[1], vtrainSAnswer.shape[2]))\n",
    "\tmodelNetwork.fit([vtrainSAnswer, vtrainTAnswer], ytrain, batch_size=100, epochs=10)\n",
    "\tpred = modelNetwork.predict([vtestSAnswer, vtestTAnswer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytestcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtest = (ytestcat[ytest.argmax(1)]).reshape(len(ytest),1)\n",
    "rpred = (ytestcat[pred.argmax(1)]).reshape(len(pred),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(rtest, rpred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohen_kappa_score(ytest, np.floor(pred), weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.876923076923077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(rtest, rpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974358974358974"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(rtest, rpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
