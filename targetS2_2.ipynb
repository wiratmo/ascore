{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, cwd)\n",
    "from module.importData import importData\n",
    "from module.toWordList import toWordList\n",
    "from module.steamingWiki import steamingWiki\n",
    "from module.makeModelGensim import makeModelGensim\n",
    "from module.toVectore import toVectore\n",
    "#from module.modelLSTM import modelLSTM\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.get_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiSource\t\t\t= 'idwiki'\n",
    "answerData\t\t\t= 'DataAnswerExam_SMP.csv'\n",
    "questionData\t\t= 'qes.csv'\n",
    "dirData\t\t\t\t= cwd+'/data/'\n",
    "corpusInput\t\t\t= wikiSource+'.bz2'\n",
    "wikiOutput\t\t\t= wikiSource+'.txt'\n",
    "fileExtension\t\t= 'bin'\n",
    "trainingAlgoritm\t= 0\n",
    "numDimension\t\t= 200\n",
    "modelOutput\t\t\t= wikiSource+'_word2vec_'+str(numDimension)+'_'+str(trainingAlgoritm)+'.'+fileExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dAnswer, dQuestion = importData(answer= dirData+answerData, question= dirData+questionData).openData()\n",
    "\n",
    "if not(os.path.exists(dirData+modelOutput)):\n",
    "\tif not(os.path.exists(dirData+wikiOutput)):\n",
    "\t\tsteamingWiki(corpusInput=corpusInput, wikiOutput=wikiOutput).execute()\n",
    "\tmakeModelGensim(wikiOutput=wikiOutput, modelOutput=modelOutput, numDimension=numDimension, trainingAlgoritm=trainingAlgoritm).execute()\n",
    "\n",
    "if fileExtension != 'bin':\n",
    "\tmodel = gensim.models.word2vec.Word2Vec.load(dirData+modelOutput)\n",
    "else:\n",
    "\tmodel = gensim.models.KeyedVectors.load_word2vec_format(dirData+modelOutput, unicode_errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal = KFold(n_splits=2, random_state=True, shuffle=True)\n",
    "\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay_id</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>3</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1</td>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>4</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Essay_id                                             Answer  Score  \\\n",
       "0           1  Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...      3   \n",
       "120         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "365         1  alumni; argument; hasil; example; teknik; imaj...      4   \n",
       "650         1  alumnus; agenda; laba; sampel; teknik; imajina...      5   \n",
       "125         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dAnswer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = dAnswer.loc[:,['Answer','TrueAnswer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Answer  \\\n",
       "0    Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...   \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "365  alumni; argument; hasil; example; teknik; imaj...   \n",
       "650  alumnus; agenda; laba; sampel; teknik; imajina...   \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.to_categorical(dAnswer.loc[:,['Score']], num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelLSTM(object):\n",
    "\tfrom keras.models import Sequential, Model\n",
    "\tfrom keras.layers import LSTM, Dense, Dropout, Bidirectional, Lambda, Dot, Subtract\n",
    "\timport keras.backend as K\n",
    "\tfrom keras import optimizers\n",
    "\n",
    "\tdef biSiamenseModel(self, inputD, distance=False):\n",
    "\n",
    "\t\tfrom keras.layers import Input, concatenate, subtract, dot\n",
    "\t\tfrom keras import backend as K\n",
    "        \n",
    "\t\tdef cosine_distance(vests):\n",
    "\t\t\tx, y = vests\n",
    "\t\t\tx = K.l2_normalize(x, axis=-1)\n",
    "\t\t\ty = K.l2_normalize(y, axis=-1)\n",
    "\t\t\treturn -K.mean(x * y, axis=-1, keepdims=True)\n",
    "        \n",
    "\t\tdef euclidean_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\tsum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "\t\t\treturn K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\t\tdef manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.sum((K.abs(x - y)), axis=1, keepdims=True)\n",
    "\n",
    "\t\tdef exponent_neg_manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.exp(-K.sum(K.abs(x-y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "\t\tMA = Input(shape= inputD, dtype=\"float32\")\n",
    "\t\tMB = Input(shape= inputD, dtype=\"float32\")\n",
    "\n",
    "\t\tx = self.Bidirectional(self.LSTM(200, dropout=0.2, recurrent_dropout=0.2), input_shape=inputD)(MA)\n",
    "\n",
    "\t\ty = self.Bidirectional(self.LSTM(200, dropout=0.2, recurrent_dropout=0.2), input_shape=inputD)(MB)\n",
    "\n",
    "\t\t# a2 = (self.Lambda(function=lambda a: euclidean_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\n",
    "\t\tif distance:\n",
    "\t\t\ta2 = (self.Lambda(function=lambda a: cosine_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\t\telse:\n",
    "\t\t\t#a2 = concatenate([x,y])\n",
    "\t\t\ta2 = self.Subtract()([x,y])\n",
    "\t\t\n",
    "\t\tout = self.Dense(4, activation='softmax')(a2)\n",
    "\n",
    "\t\tmodel = self.Model(inputs=[MA, MB], outputs=out)\n",
    "\t\tadam = self.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\t\tmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['mae'])\n",
    "\n",
    "\t\tmodel.summary()\n",
    "\n",
    "\t\treturn model\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 400)          641600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 400)          641600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               ([(None, 400), (None 0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 ([(None, 400), (None 8           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,283,208\n",
      "Trainable params: 1,283,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 6s 16ms/step - loss: 1.3846 - mean_absolute_error: 0.3748\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3806 - mean_absolute_error: 0.3743\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3767 - mean_absolute_error: 0.3738\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3729 - mean_absolute_error: 0.3733\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3692 - mean_absolute_error: 0.3728\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3657 - mean_absolute_error: 0.3724\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3621 - mean_absolute_error: 0.3719\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3585 - mean_absolute_error: 0.3714\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3550 - mean_absolute_error: 0.3710\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3513 - mean_absolute_error: 0.3705\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 400)          641600      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 400)          641600      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               ([(None, 400), (None 0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 ([(None, 400), (None 8           lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,283,208\n",
      "Trainable params: 1,283,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.3850 - mean_absolute_error: 0.3748\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3811 - mean_absolute_error: 0.3743\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3774 - mean_absolute_error: 0.3739\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3736 - mean_absolute_error: 0.3734\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3698 - mean_absolute_error: 0.3729\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3662 - mean_absolute_error: 0.3724\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3625 - mean_absolute_error: 0.3720\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3588 - mean_absolute_error: 0.3715\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 3s 7ms/step - loss: 1.3553 - mean_absolute_error: 0.3710\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 3s 8ms/step - loss: 1.3516 - mean_absolute_error: 0.3705\n"
     ]
    }
   ],
   "source": [
    "for dx, dy in crossVal.split(dAnswer):\n",
    "\n",
    "\ttrainSAnswer = []\n",
    "\ttrainTAnswer = []\n",
    "\ttestSAnswer = []\n",
    "\ttestTAnswer = []\n",
    "\t\n",
    "\tprint(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\ttrain, test= dAnswer.iloc[dx], dAnswer.iloc[dy]\n",
    "\t\n",
    "\t\n",
    "\txtrain = train.loc[:,['Answer', 'TrueAnswer']]\n",
    "\txtest = test.loc[:,['Answer', 'TrueAnswer']]\n",
    "\tytraincat, idtrain = np.unique(train.loc[:,['Score']].values, return_inverse=True)\n",
    "\tytrain = keras.utils.to_categorical(idtrain, len(ytraincat))\n",
    "\tytestcat, idtest = np.unique(test.loc[:,['Score']].values, return_inverse=True)\n",
    "\tytest = keras.utils.to_categorical(idtest, len(ytestcat))\n",
    "\t#ytrain = keras.utils.to_categorical(train.loc[:,['Score']].values, num_classes=6)\n",
    "\t#ytest = keras.utils.to_categorical(test.loc[:,['Score']].values, num_classes=6)\n",
    "\t\n",
    "\t# bagian ini biar universal aja.\n",
    "\t\n",
    "\t[trainSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['Answer']].values]\n",
    "\t[trainTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['TrueAnswer']].values]\n",
    "\t[testSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['Answer']].values]\n",
    "\t[testTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['TrueAnswer']].values]\n",
    "\t\n",
    "\tvtrainSAnswer, vtrainTAnswer = toVectore(essays = trainSAnswer, trueAnswer=trainTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tvtestSAnswer, vtestTAnswer = toVectore(essays = testSAnswer, trueAnswer=testTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tmodelNetwork = modelLSTM().biSiamenseModel(inputD=(vtrainSAnswer.shape[1], vtrainSAnswer.shape[2]), distance=True)\n",
    "\tmodelNetwork.fit([vtrainSAnswer, vtrainTAnswer], ytrain, batch_size=100, epochs=10)\n",
    "\tpred = modelNetwork.predict([vtestSAnswer, vtestTAnswer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytestcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtest = (ytestcat[ytest.argmax(1)]).reshape(len(ytest),1)\n",
    "rpred = (ytestcat[pred.argmax(1)]).reshape(len(pred),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(rtest, rpred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohen_kappa_score(ytest, np.floor(pred), weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.876923076923077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(rtest, rpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974358974358974"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(rtest, rpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
