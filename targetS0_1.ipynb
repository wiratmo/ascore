{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "sys.path.insert(0, cwd)\n",
    "from module.importData import importData\n",
    "from module.toWordList import toWordList\n",
    "from module.steamingWiki import steamingWiki\n",
    "from module.makeModelGensim import makeModelGensim\n",
    "from module.toVectore import toVectore\n",
    "#from module.modelLSTM import modelLSTM\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.get_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiSource\t\t\t= 'idwiki'\n",
    "answerData\t\t\t= 'DataAnswerExam_SMP.csv'\n",
    "questionData\t\t= 'qes.csv'\n",
    "dirData\t\t\t\t= cwd+'/data/'\n",
    "corpusInput\t\t\t= wikiSource+'.bz2'\n",
    "wikiOutput\t\t\t= wikiSource+'.txt'\n",
    "fileExtension\t\t= 'bin'\n",
    "trainingAlgoritm\t= 0\n",
    "numDimension\t\t= 200\n",
    "modelOutput\t\t\t= wikiSource+'_word2vec_'+str(numDimension)+'_'+str(trainingAlgoritm)+'.'+fileExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dAnswer, dQuestion = importData(answer= dirData+answerData, question= dirData+questionData).openData()\n",
    "\n",
    "if not(os.path.exists(dirData+modelOutput)):\n",
    "\tif not(os.path.exists(dirData+wikiOutput)):\n",
    "\t\tsteamingWiki(corpusInput=corpusInput, wikiOutput=wikiOutput).execute()\n",
    "\tmakeModelGensim(wikiOutput=wikiOutput, modelOutput=modelOutput, numDimension=numDimension, trainingAlgoritm=trainingAlgoritm).execute()\n",
    "\n",
    "if fileExtension != 'bin':\n",
    "\tmodel = gensim.models.word2vec.Word2Vec.load(dirData+modelOutput)\n",
    "else:\n",
    "\tmodel = gensim.models.KeyedVectors.load_word2vec_format(dirData+modelOutput, unicode_errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal = KFold(n_splits=2, random_state=True, shuffle=True)\n",
    "\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay_id</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Score</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>3</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1</td>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>4</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>5</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Essay_id                                             Answer  Score  \\\n",
       "0           1  Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...      3   \n",
       "120         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "365         1  alumni; argument; hasil; example; teknik; imaj...      4   \n",
       "650         1  alumnus; agenda; laba; sampel; teknik; imajina...      5   \n",
       "125         1  lulusan : alumnus; rencana : agenda; keuntunga...      5   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dAnswer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = dAnswer.loc[:,['Answer','TrueAnswer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>TrueAnswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>alumni; argument; hasil; example; teknik; imaj...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>alumnus; agenda; laba; sampel; teknik; imajina...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "      <td>lulusan : alumnus; rencana : agenda; keuntunga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Answer  \\\n",
       "0    Alumni;  ; Kelebihan; Permisalan; Tutorial; Im...   \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "365  alumni; argument; hasil; example; teknik; imaj...   \n",
       "650  alumnus; agenda; laba; sampel; teknik; imajina...   \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...   \n",
       "\n",
       "                                            TrueAnswer  \n",
       "0    lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "120  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "365  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "650  lulusan : alumnus; rencana : agenda; keuntunga...  \n",
       "125  lulusan : alumnus; rencana : agenda; keuntunga...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.to_categorical(dAnswer.loc[:,['Score']], num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelLSTM(object):\n",
    "\tfrom keras.models import Sequential, Model\n",
    "\tfrom keras.layers import LSTM, Dense, Dropout, Bidirectional, Lambda, Dot, Subtract\n",
    "\timport keras.backend as K\n",
    "\tfrom keras import optimizers\n",
    "\n",
    "\tdef biSiamenseModel(self, inputD, euclidean=False):\n",
    "\n",
    "\t\tfrom keras.layers import Input, concatenate, subtract, dot\n",
    "\t\tfrom keras import backend as K\n",
    "\n",
    "\t\tdef euclidean_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\tsum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "\t\t\treturn K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\t\tdef manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.sum((K.abs(x - y)), axis=1, keepdims=True)\n",
    "\n",
    "\t\tdef exponent_neg_manhattan_distance(vects):\n",
    "\t\t\tx, y = vects\n",
    "\t\t\treturn K.exp(-K.sum(K.abs(x-y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "\t\tMA = Input(shape= inputD, dtype=\"float32\")\n",
    "\t\tMB = Input(shape= inputD, dtype=\"float32\")\n",
    "\n",
    "\t\tx = self.Bidirectional(self.LSTM(200, dropout=0.2, recurrent_dropout=0.2, return_sequences=True), input_shape=inputD)(MA)\n",
    "\t\tx = self.Bidirectional(self.LSTM(150, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "\n",
    "\t\ty = self.Bidirectional(self.LSTM(200, dropout=0.2, recurrent_dropout=0.2, return_sequences=True), input_shape=inputD)(MB)\n",
    "\t\ty = self.Bidirectional(self.LSTM(150, dropout=0.2, recurrent_dropout=0.2))(y)\n",
    "\t\t# a2 = (self.Lambda(function=lambda a: euclidean_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\n",
    "\t\tif euclidean:\n",
    "\t\t\ta2 = (self.Lambda(function=lambda a: euclidean_distance(a),output_shape=lambda a: (a,1)))([x,y])\n",
    "\t\telse:\n",
    "\t\t\t#a2 = concatenate([x,y])\n",
    "\t\t\ta2 = self.Subtract()([x,y])\n",
    "\t\t\n",
    "\t\tout = self.Dense(1, activation='relu')(a2)\n",
    "\n",
    "\t\tmodel = self.Model(inputs=[MA, MB], outputs=out)\n",
    "\t\tsgd = self.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\t\tmodel.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mae'])\n",
    "\n",
    "\t\tmodel.summary()\n",
    "\n",
    "\t\treturn model\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 180, 400)     641600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 180, 400)     641600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 300)          661200      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 300)          661200      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 300)          0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            301         subtract_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,605,901\n",
      "Trainable params: 2,605,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\s2\\Anaconda3\\envs\\tgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 12s 31ms/step - loss: 8.5752 - mean_absolute_error: 2.4334\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 6s 16ms/step - loss: 1.4781 - mean_absolute_error: 0.9568\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 1.0860 - mean_absolute_error: 0.8476\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.9264 - mean_absolute_error: 0.7256\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7705 - mean_absolute_error: 0.6496\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6842 - mean_absolute_error: 0.6220\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5766 - mean_absolute_error: 0.5553\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4815 - mean_absolute_error: 0.4974\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.4399 - mean_absolute_error: 0.4801\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4386 - mean_absolute_error: 0.4766\n",
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 180, 200)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 180, 400)     641600      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 180, 400)     641600      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 300)          661200      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 300)          661200      bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 300)          0           bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            301         subtract_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,605,901\n",
      "Trainable params: 2,605,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "390/390 [==============================] - 11s 28ms/step - loss: 10.0581 - mean_absolute_error: 2.7408\n",
      "Epoch 2/10\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.5639 - mean_absolute_error: 0.9630\n",
      "Epoch 3/10\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1388 - mean_absolute_error: 0.8802\n",
      "Epoch 4/10\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9943 - mean_absolute_error: 0.7640\n",
      "Epoch 5/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.8876 - mean_absolute_error: 0.7184\n",
      "Epoch 6/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.7267 - mean_absolute_error: 0.6483\n",
      "Epoch 7/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.6401 - mean_absolute_error: 0.5714\n",
      "Epoch 8/10\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.5743 - mean_absolute_error: 0.5622\n",
      "Epoch 9/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5068 - mean_absolute_error: 0.4868\n",
      "Epoch 10/10\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4794 - mean_absolute_error: 0.4896\n"
     ]
    }
   ],
   "source": [
    "for dx, dy in crossVal.split(dAnswer):\n",
    "\n",
    "\ttrainSAnswer = []\n",
    "\ttrainTAnswer = []\n",
    "\ttestSAnswer = []\n",
    "\ttestTAnswer = []\n",
    "\t\n",
    "\tprint(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "\ttrain, test= dAnswer.iloc[dx], dAnswer.iloc[dy]\n",
    "\t\n",
    "\t\n",
    "\txtrain = train.loc[:,['Answer', 'TrueAnswer']]\n",
    "\txtest = test.loc[:,['Answer', 'TrueAnswer']]\n",
    "\tytrain = train.loc[:,['Score']].values\n",
    "\tytest = test.loc[:,['Score']].values\n",
    "\t#ytraincat, idtrain = np.unique(train.loc[:,['Score']].values, return_inverse=True)\n",
    "\t#ytrain = keras.utils.to_categorical(idtrain, len(ytraincat))\n",
    "\t#ytestcat, idtest = np.unique(test.loc[:,['Score']].values, return_inverse=True)\n",
    "\t#ytest = keras.utils.to_categorical(idtest, len(ytestcat))\n",
    "\t#ytrain = keras.utils.to_categorical(train.loc[:,['Score']].values, num_classes=6)\n",
    "\t#ytest = keras.utils.to_categorical(test.loc[:,['Score']].values, num_classes=6)\n",
    "\t\n",
    "\t# bagian ini biar universal aja.\n",
    "\t\n",
    "\t[trainSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['Answer']].values]\n",
    "\t[trainTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtrain.loc[:,['TrueAnswer']].values]\n",
    "\t[testSAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['Answer']].values]\n",
    "\t[testTAnswer.append(toWordList().sentenceToWordList(a1[0], changeNumber2Word= True)) for a1 in xtest.loc[:,['TrueAnswer']].values]\n",
    "\t\n",
    "\tvtrainSAnswer, vtrainTAnswer = toVectore(essays = trainSAnswer, trueAnswer=trainTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tvtestSAnswer, vtestTAnswer = toVectore(essays = testSAnswer, trueAnswer=testTAnswer, model = model, numFeature= numDimension, average=False, distance=True).changeToVector()\n",
    "\tmodelNetwork = modelLSTM().biSiamenseModel(inputD=(vtrainSAnswer.shape[1], vtrainSAnswer.shape[2]))\n",
    "\tmodelNetwork.fit([vtrainSAnswer, vtrainTAnswer], ytrain, batch_size=100, epochs=10)\n",
    "\tpred = modelNetwork.predict([vtestSAnswer, vtestTAnswer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6830400345757426"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(ytest, np.around(pred), weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871794871794871"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, np.around(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5743589743589743"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ytest, np.around(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [4],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [4],\n",
       "       [5]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.375099 ],\n",
       "       [4.046815 ],\n",
       "       [5.5191174],\n",
       "       [5.5527253],\n",
       "       [5.292536 ],\n",
       "       [5.224403 ],\n",
       "       [5.5021586],\n",
       "       [5.6024194],\n",
       "       [5.433441 ],\n",
       "       [5.457258 ],\n",
       "       [5.494593 ],\n",
       "       [4.6552052],\n",
       "       [5.153135 ],\n",
       "       [5.4933715],\n",
       "       [4.7852006],\n",
       "       [5.2595716],\n",
       "       [5.6024194],\n",
       "       [5.420472 ],\n",
       "       [5.166968 ],\n",
       "       [5.5693226],\n",
       "       [5.6024194],\n",
       "       [5.5592256],\n",
       "       [5.6340246],\n",
       "       [4.8029966],\n",
       "       [5.448654 ],\n",
       "       [5.6024194],\n",
       "       [5.6024194],\n",
       "       [5.4537477],\n",
       "       [5.479692 ],\n",
       "       [5.6329923],\n",
       "       [5.6024194],\n",
       "       [5.6024194],\n",
       "       [5.6024194],\n",
       "       [5.514079 ],\n",
       "       [5.406247 ],\n",
       "       [5.4707274],\n",
       "       [5.3940363],\n",
       "       [5.4619923],\n",
       "       [5.2864294],\n",
       "       [5.1142993],\n",
       "       [5.6024194],\n",
       "       [5.4943447],\n",
       "       [5.6024194],\n",
       "       [5.2521195],\n",
       "       [5.2737117],\n",
       "       [5.2567887],\n",
       "       [5.4697413],\n",
       "       [5.6024194],\n",
       "       [5.125488 ],\n",
       "       [5.6024194],\n",
       "       [5.009499 ],\n",
       "       [5.6024194],\n",
       "       [5.6201177],\n",
       "       [5.6024194],\n",
       "       [5.525564 ],\n",
       "       [5.34449  ],\n",
       "       [5.450699 ],\n",
       "       [5.3305483],\n",
       "       [5.6024194],\n",
       "       [5.463219 ],\n",
       "       [4.8699894],\n",
       "       [3.7510297],\n",
       "       [4.2479877],\n",
       "       [5.915035 ],\n",
       "       [4.0979705],\n",
       "       [6.36992  ],\n",
       "       [4.2345743],\n",
       "       [5.6773734],\n",
       "       [4.741512 ],\n",
       "       [5.5742373],\n",
       "       [1.2663374],\n",
       "       [3.3359704],\n",
       "       [6.003913 ],\n",
       "       [5.794577 ],\n",
       "       [6.1034536],\n",
       "       [5.819214 ],\n",
       "       [2.9347749],\n",
       "       [1.6133382],\n",
       "       [5.620515 ],\n",
       "       [5.7723117],\n",
       "       [5.0789585],\n",
       "       [3.7200372],\n",
       "       [5.1741886],\n",
       "       [3.349886 ],\n",
       "       [1.5880587],\n",
       "       [1.7719882],\n",
       "       [4.4051914],\n",
       "       [3.6577678],\n",
       "       [5.146693 ],\n",
       "       [4.5146275],\n",
       "       [3.2866218],\n",
       "       [6.0206647],\n",
       "       [1.6561403],\n",
       "       [1.7338053],\n",
       "       [5.4798694],\n",
       "       [5.8492055],\n",
       "       [2.8900428],\n",
       "       [5.823347 ],\n",
       "       [2.1976542],\n",
       "       [5.088883 ],\n",
       "       [5.9584794],\n",
       "       [4.8585362],\n",
       "       [2.7787352],\n",
       "       [5.5853066],\n",
       "       [1.8508387],\n",
       "       [5.7454176],\n",
       "       [5.9058886],\n",
       "       [6.348736 ],\n",
       "       [5.9424906],\n",
       "       [5.357312 ],\n",
       "       [6.3660526],\n",
       "       [5.640063 ],\n",
       "       [5.491685 ],\n",
       "       [4.25133  ],\n",
       "       [1.8289373],\n",
       "       [5.834197 ],\n",
       "       [5.6133246],\n",
       "       [5.966854 ],\n",
       "       [5.849401 ],\n",
       "       [5.850871 ],\n",
       "       [4.619934 ],\n",
       "       [5.4574695],\n",
       "       [2.592457 ],\n",
       "       [6.1772566],\n",
       "       [4.4630885],\n",
       "       [4.2027316],\n",
       "       [3.349886 ],\n",
       "       [2.1385217],\n",
       "       [2.430106 ],\n",
       "       [2.5658286],\n",
       "       [4.9873056],\n",
       "       [3.9927306],\n",
       "       [3.5327291],\n",
       "       [4.291039 ],\n",
       "       [5.2485027],\n",
       "       [5.4620876],\n",
       "       [2.685201 ],\n",
       "       [5.273694 ],\n",
       "       [5.200937 ],\n",
       "       [5.1771703],\n",
       "       [5.2380753],\n",
       "       [5.166852 ],\n",
       "       [4.5552354],\n",
       "       [5.234947 ],\n",
       "       [5.146905 ],\n",
       "       [5.2505484],\n",
       "       [5.1874933],\n",
       "       [5.222746 ],\n",
       "       [5.242779 ],\n",
       "       [5.1893425],\n",
       "       [5.1893425],\n",
       "       [5.2042775],\n",
       "       [5.1893425],\n",
       "       [5.1893425],\n",
       "       [5.2646184],\n",
       "       [4.861528 ],\n",
       "       [5.1584854],\n",
       "       [5.1493745],\n",
       "       [5.091176 ],\n",
       "       [5.1893425],\n",
       "       [5.1893425],\n",
       "       [5.1262116],\n",
       "       [5.1262116],\n",
       "       [5.1262116],\n",
       "       [5.2164516],\n",
       "       [5.1919737],\n",
       "       [5.1893425],\n",
       "       [5.155229 ],\n",
       "       [5.228502 ],\n",
       "       [5.1893425],\n",
       "       [5.1893425],\n",
       "       [5.1262116],\n",
       "       [5.2052007],\n",
       "       [5.2341604],\n",
       "       [5.242035 ],\n",
       "       [5.1262116],\n",
       "       [5.1893425],\n",
       "       [5.268157 ],\n",
       "       [4.8342986],\n",
       "       [5.1893425],\n",
       "       [5.2395473],\n",
       "       [5.1893425],\n",
       "       [5.1262116],\n",
       "       [5.155229 ],\n",
       "       [4.811761 ],\n",
       "       [5.1893425],\n",
       "       [5.242035 ],\n",
       "       [5.1893425],\n",
       "       [5.2505484],\n",
       "       [5.3975067],\n",
       "       [5.234947 ],\n",
       "       [5.2052007],\n",
       "       [5.1893425],\n",
       "       [4.8492537],\n",
       "       [5.2164516],\n",
       "       [4.676398 ],\n",
       "       [4.700934 ],\n",
       "       [5.222746 ],\n",
       "       [5.209628 ],\n",
       "       [5.222746 ],\n",
       "       [4.9925556],\n",
       "       [5.1893425],\n",
       "       [5.1893425],\n",
       "       [4.967629 ],\n",
       "       [5.237975 ],\n",
       "       [5.188915 ],\n",
       "       [5.1893425],\n",
       "       [5.1408916],\n",
       "       [5.425115 ],\n",
       "       [5.2130866],\n",
       "       [5.434782 ],\n",
       "       [5.4593153],\n",
       "       [5.434782 ],\n",
       "       [5.4245186],\n",
       "       [5.3367515],\n",
       "       [5.4270697],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.425115 ],\n",
       "       [5.4593153],\n",
       "       [5.2697535],\n",
       "       [5.376218 ],\n",
       "       [5.4011655],\n",
       "       [5.4505286],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.4153886],\n",
       "       [5.434782 ],\n",
       "       [5.432908 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.180199 ],\n",
       "       [5.425115 ],\n",
       "       [5.434782 ],\n",
       "       [5.4066167],\n",
       "       [5.3822093],\n",
       "       [5.4066167],\n",
       "       [5.1692066],\n",
       "       [5.4505286],\n",
       "       [5.426567 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.4505286],\n",
       "       [5.425115 ],\n",
       "       [5.442292 ],\n",
       "       [5.4270697],\n",
       "       [5.434782 ],\n",
       "       [5.408994 ],\n",
       "       [5.235275 ],\n",
       "       [5.221995 ],\n",
       "       [5.434782 ],\n",
       "       [5.434782 ],\n",
       "       [5.408994 ],\n",
       "       [5.221995 ],\n",
       "       [5.383022 ],\n",
       "       [5.4593153],\n",
       "       [5.425115 ],\n",
       "       [5.4484777],\n",
       "       [5.434782 ],\n",
       "       [5.425115 ],\n",
       "       [5.408994 ],\n",
       "       [5.2151423],\n",
       "       [5.434782 ],\n",
       "       [5.3822093],\n",
       "       [5.4593153],\n",
       "       [5.3932023],\n",
       "       [5.045337 ],\n",
       "       [5.161889 ],\n",
       "       [5.434782 ],\n",
       "       [5.299583 ],\n",
       "       [4.7850695],\n",
       "       [3.984436 ],\n",
       "       [4.4125347],\n",
       "       [3.8078272],\n",
       "       [4.2045794],\n",
       "       [5.672542 ],\n",
       "       [2.3463643],\n",
       "       [4.576869 ],\n",
       "       [5.4828825],\n",
       "       [5.288925 ],\n",
       "       [3.5817482],\n",
       "       [5.5606065],\n",
       "       [3.1109786],\n",
       "       [2.146732 ],\n",
       "       [1.3719072],\n",
       "       [4.6781616],\n",
       "       [3.0325522],\n",
       "       [1.2647872],\n",
       "       [5.1429358],\n",
       "       [3.423774 ],\n",
       "       [4.194743 ],\n",
       "       [2.9884264],\n",
       "       [1.4797237],\n",
       "       [3.11251  ],\n",
       "       [5.1354485],\n",
       "       [2.2855253],\n",
       "       [2.651426 ],\n",
       "       [4.414652 ],\n",
       "       [4.910681 ],\n",
       "       [4.178533 ],\n",
       "       [1.8633437],\n",
       "       [2.743334 ],\n",
       "       [3.4463098],\n",
       "       [1.7472638],\n",
       "       [4.6526713],\n",
       "       [3.4252164],\n",
       "       [5.6456213],\n",
       "       [2.9939702],\n",
       "       [5.1255145],\n",
       "       [2.7427092],\n",
       "       [3.770797 ],\n",
       "       [5.2595534],\n",
       "       [3.8836732],\n",
       "       [5.6850595],\n",
       "       [3.9014783],\n",
       "       [3.2600124],\n",
       "       [1.8655026],\n",
       "       [4.8783884],\n",
       "       [3.2817214],\n",
       "       [2.8826857],\n",
       "       [5.685089 ],\n",
       "       [4.419283 ],\n",
       "       [4.1807284],\n",
       "       [3.194211 ],\n",
       "       [5.6873603],\n",
       "       [1.9452388],\n",
       "       [0.7218006],\n",
       "       [2.9103653],\n",
       "       [3.1684887],\n",
       "       [4.2166305],\n",
       "       [5.046033 ],\n",
       "       [5.541756 ],\n",
       "       [3.2040265],\n",
       "       [3.1283228],\n",
       "       [3.3475974],\n",
       "       [5.6210766],\n",
       "       [6.1263466],\n",
       "       [5.517338 ],\n",
       "       [5.2833366],\n",
       "       [3.9417913],\n",
       "       [6.0532265],\n",
       "       [5.4938216],\n",
       "       [5.3441553],\n",
       "       [5.477975 ],\n",
       "       [5.803758 ],\n",
       "       [5.9657745],\n",
       "       [5.7851954],\n",
       "       [5.5949383],\n",
       "       [5.7917104],\n",
       "       [5.846054 ],\n",
       "       [5.2077293],\n",
       "       [5.8364687],\n",
       "       [5.8803544],\n",
       "       [5.5336933],\n",
       "       [4.9058657],\n",
       "       [4.4341016],\n",
       "       [4.5352283],\n",
       "       [5.6725802],\n",
       "       [4.609174 ],\n",
       "       [4.114881 ],\n",
       "       [5.9025555],\n",
       "       [4.916405 ],\n",
       "       [5.1212244],\n",
       "       [5.082058 ],\n",
       "       [5.736738 ],\n",
       "       [4.8638105],\n",
       "       [5.643719 ],\n",
       "       [5.822904 ],\n",
       "       [5.898038 ],\n",
       "       [5.443869 ],\n",
       "       [5.822904 ],\n",
       "       [5.822904 ],\n",
       "       [5.621297 ],\n",
       "       [5.294798 ],\n",
       "       [5.67861  ],\n",
       "       [5.884901 ],\n",
       "       [5.87963  ],\n",
       "       [4.271528 ],\n",
       "       [5.130555 ],\n",
       "       [3.7612963],\n",
       "       [4.0614862],\n",
       "       [4.895426 ],\n",
       "       [4.6296296],\n",
       "       [5.6100497],\n",
       "       [3.779889 ],\n",
       "       [4.027829 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgpu",
   "language": "python",
   "name": "tgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
